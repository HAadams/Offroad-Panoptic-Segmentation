{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import shutil\n",
    "import sys\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add parent directory to path to enable access to other scripts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Rellis-3D Data\n",
    "Change dataset_path if you want to download to a different directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(os.getcwd(), \"..\", \"datasets\", \"Rellis\")\n",
    "print(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\Rellis_3D_pylon_camera_node.zip\n"
     ]
    }
   ],
   "source": [
    "rellis_images_path = os.path.join(dataset_path, \"Rellis_3D_pylon_camera_node.zip\")\n",
    "print(rellis_images_path)\n",
    "#gdown.download(\"https://drive.google.com/uc?id=1F3Leu0H_m6aPVpZITragfreO_SGtL2yV\", rellis_images_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\Rellis_3D_pylon_camera_node_label_color.zip\n"
     ]
    }
   ],
   "source": [
    "rellis_labels_path = os.path.join(dataset_path, \"Rellis_3D_pylon_camera_node_label_color.zip\")\n",
    "print(rellis_labels_path)\n",
    "#gdown.download(\"https://drive.google.com/uc?id=1HJl8Fi5nAjOr41DPUFmkeKWtDXhCZDke\", rellis_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unzip images and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\extracted\n"
     ]
    }
   ],
   "source": [
    "rellis_extract_path = os.path.join(dataset_path, \"extracted\")\n",
    "print(rellis_extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\extracted\\images\n"
     ]
    }
   ],
   "source": [
    "rellis_images_extract_path = os.path.join(rellis_extract_path, \"images\")\n",
    "print(rellis_images_extract_path)\n",
    "#gdown.extractall(rellis_images_path, rellis_images_extract_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\extracted\\labels\n"
     ]
    }
   ],
   "source": [
    "rellis_labels_extract_path = os.path.join(rellis_extract_path, \"labels\")\n",
    "print(rellis_labels_extract_path)\n",
    "#gdown.extractall(rellis_labels_path, rellis_labels_extract_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up File Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name(filename):\n",
    "    parts = re.split(r\"\\.|/|\\\\\", str(filename))\n",
    "    return (parts[-2], parts[-1])\n",
    "\n",
    "def consolidate_files(dataset_dir, new_dir, file_ext):\n",
    "    if not os.path.exists(new_dir):\n",
    "        os.mkdir(new_dir)\n",
    "        files = list(pathlib.Path(dataset_dir).glob(f\"**/*.{file_ext}\"))\n",
    "        print(f\"{len(files)} files with extension .{file_ext} found\")\n",
    "        for f in tqdm(files):\n",
    "            file_name = \".\".join(split_name(f))\n",
    "            shutil.move(f, os.path.join(new_dir, file_name))\n",
    "    else:\n",
    "        print(f\"Directory already exists at path: {new_dir}\")\n",
    "\n",
    "def remove_unpaired_images(image_dir, label_dir):\n",
    "    if not os.path.exists(image_dir) or not os.path.exists(label_dir):\n",
    "        return\n",
    "    \n",
    "    image_set = set(split_name(image)[0] for image in pathlib.Path(image_dir).glob(\"*\"))\n",
    "    label_set = set(split_name(label)[0] for label in pathlib.Path(label_dir).glob(\"*\"))\n",
    "    unpaired_images = image_set.difference(label_set)\n",
    "    print(f\"Deleting {len(unpaired_images)} unpaired images\")\n",
    "\n",
    "    for im in unpaired_images:\n",
    "        image_path = os.path.join(image_dir, f\"{im}.jpg\")\n",
    "        if os.path.exists(image_path):\n",
    "            os.remove(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\images\n",
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\n"
     ]
    }
   ],
   "source": [
    "rellis_processed_images_path = os.path.join(dataset_path, \"images\")\n",
    "print(rellis_processed_images_path)\n",
    "rellis_processed_labels_path = os.path.join(dataset_path, \"labels\")\n",
    "print(rellis_processed_labels_path)\n",
    "\n",
    "#consolidate_files(rellis_extract_path, rellis_processed_images_path, \"jpg\")\n",
    "#consolidate_files(rellis_extract_path, rellis_processed_labels_path, \"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_unpaired_images(rellis_processed_images_path, rellis_processed_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_splits(image_dir, test_size=0.10, val_size=0.05, random_state=123):\n",
    "    files = [split_name(filename)[0] for filename in pathlib.Path(image_dir).glob(\"*\")]\n",
    "    actual_test_size = val_size + test_size\n",
    "    actual_val_size  = val_size / actual_test_size\n",
    "    train, test = train_test_split(files, test_size=actual_test_size, random_state=random_state)\n",
    "    test, val   = train_test_split(test,  test_size=actual_val_size,  random_state=random_state)\n",
    "    print(len(train), len(test), len(val))\n",
    "    return train, test, val\n",
    "\n",
    "def make_data_dirs(image_dir, label_dir):\n",
    "    for dir_name in [image_dir, label_dir]:\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.mkdir(dir_name)\n",
    "        for split_name in [\"train\", \"test\", \"val\"]:\n",
    "            split_dir = os.path.join(dir_name, split_name)\n",
    "            if not os.path.exists(split_dir):\n",
    "                os.mkdir(split_dir)\n",
    "\n",
    "def move_files(train, test, val, image_dir, label_dir):\n",
    "    make_data_dirs(image_dir, label_dir)\n",
    "\n",
    "    for dir_name, data_split in [(\"train\", train), (\"test\", test), (\"val\", val)]:\n",
    "        for filename in tqdm(data_split, desc=dir_name):\n",
    "            image_name = f\"{filename}.jpg\"\n",
    "            label_name = f\"{filename}.png\"\n",
    "\n",
    "            shutil.move(\n",
    "                os.path.join(image_dir, image_name),\n",
    "                os.path.join(image_dir, dir_name, image_name)\n",
    "            )\n",
    "            shutil.move(\n",
    "                os.path.join(label_dir, label_name),\n",
    "                os.path.join(label_dir, dir_name, label_name)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train, test, val = get_data_splits(rellis_processed_images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move_files(train, test, val, rellis_processed_images_path, rellis_processed_labels_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Instance Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\.venv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from createPanopticInstanceIds import main as cpii_main\n",
    "#cpii_main([rellis_processed_labels_path, \"rellis\", 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Panoptic Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5298/5298 [02:00<00:00, 44.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_train_panoptic.json\n",
      "TOOK 121.38004541397095 SECONDS!\n"
     ]
    }
   ],
   "source": [
    "from createPanopticAnnotationsParallel import main as cpa_main\n",
    "\n",
    "processed_labels_train_path = os.path.join(rellis_processed_labels_path, \"train\")\n",
    "print(processed_labels_train_path)\n",
    "#cpa_main([processed_labels_train_path, \"rellis\", 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 624/624 [00:14<00:00, 42.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_test_panoptic.json\n",
      "TOOK 15.083001613616943 SECONDS!\n"
     ]
    }
   ],
   "source": [
    "processed_labels_test_path = os.path.join(rellis_processed_labels_path, \"test\")\n",
    "print(processed_labels_test_path)\n",
    "#cpa_main([processed_labels_test_path, \"rellis\", 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\val\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 312/312 [00:07<00:00, 39.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_val_panoptic.json\n",
      "TOOK 8.12700366973877 SECONDS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed_labels_val_path = os.path.join(rellis_processed_labels_path, \"val\")\n",
    "print(processed_labels_val_path)\n",
    "#cpa_main([processed_labels_val_path, \"rellis\", 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Instance Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Panoptic Images: 100%|██████████| 5298/5298 [08:23<00:00, 10.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_train_instances.json\n",
      "TOOK 504.6814215183258 SECONDS!\n"
     ]
    }
   ],
   "source": [
    "from createInstances import main as ci_main\n",
    "\n",
    "ci_main([processed_labels_train_path, \"rellis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Panoptic Images: 100%|██████████| 624/624 [00:59<00:00, 10.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_test_instances.json\n",
      "TOOK 59.643972635269165 SECONDS!\n"
     ]
    }
   ],
   "source": [
    "ci_main([processed_labels_test_path, \"rellis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Panoptic Images: 100%|██████████| 312/312 [00:27<00:00, 11.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving the json file d:\\Github Repos\\SJSU\\Offroad-Panoptic-Segmentation\\notebooks\\..\\datasets\\Rellis\\labels\\annotations_val_instances.json\n",
      "TOOK 27.86100673675537 SECONDS!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ci_main([processed_labels_val_path, \"rellis\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Semantic Segmentation Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'panopticapi'...\n"
     ]
    }
   ],
   "source": [
    "#!git clone https://github.com/cocodataset/panopticapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/cocodataset/panopticapi.git\n",
      "  Cloning https://github.com/cocodataset/panopticapi.git to c:\\users\\nated\\appdata\\local\\temp\\pip-req-build-dyin71xx\n",
      "  Resolved https://github.com/cocodataset/panopticapi.git to commit 7bb4655548f98f3fedc07bf37e9040a992b054b0\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in d:\\github repos\\sjsu\\cmpe295\\.venv\\lib\\site-packages (from panopticapi==0.1) (1.22.3)\n",
      "Requirement already satisfied: Pillow in d:\\github repos\\sjsu\\cmpe295\\.venv\\lib\\site-packages (from panopticapi==0.1) (9.1.0)\n",
      "Using legacy 'setup.py install' for panopticapi, since package 'wheel' is not installed.\n",
      "Installing collected packages: panopticapi\n",
      "  Running setup.py install for panopticapi: started\n",
      "  Running setup.py install for panopticapi: finished with status 'done'\n",
      "Successfully installed panopticapi-0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/cocodataset/panopticapi.git 'C:\\Users\\nated\\AppData\\Local\\Temp\\pip-req-build-dyin71xx'\n"
     ]
    }
   ],
   "source": [
    "#%pip install git+https://github.com/cocodataset/panopticapi.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING FROM...\n",
      "COCO panoptic format:\n",
      "\tSegmentation folder: Rellis_labels/val_panoptic/\n",
      "\tJSON file: Rellis_labels/annotations_val_panoptic.json\n",
      "SEMANTIC SEGMENTATION\n",
      "in PNG format:\n",
      "\tFolder with semnatic segmentations: Rellis_labels/val_semantic\n",
      "Creating folder Rellis_labels/val_semantic for semantic segmentation PNGs\n",
      "\n",
      "\n",
      "Number of cores: 20, images per core: 16\n",
      "Core: 0, 0 from 16 images processed\n",
      "Core: 1, 0 from 16 images processed\n",
      "Core: 2, 0 from 16 images processed\n",
      "Core: 3, 0 from 16 images processed\n",
      "Core: 4, 0 from 16 images processed\n",
      "Core: 5, 0 from 16 images processed\n",
      "Core: 6, 0 from 16 images processed\n",
      "Core: 7, 0 from 16 images processed\n",
      "Core: 8, 0 from 16 images processed\n",
      "Core: 9, 0 from 16 images processed\n",
      "Core: 10, 0 from 16 images processed\n",
      "Core: 11, 0 from 15 images processed\n",
      "Core: 12, 0 from 15 images processed\n",
      "Core: 13, 0 from 15 images processed\n",
      "Core: 14, 0 from 15 images processed\n",
      "Core: 15, 0 from 15 images processed\n",
      "Core: 16, 0 from 15 images processed\n",
      "Core: 17, 0 from 15 images processed\n",
      "Core: 18, 0 from 15 images processed\n",
      "Core: 19, 0 from 15 images processed\n",
      "Core: 15, all 15 images processed\n",
      "Core: 14, all 15 images processed\n",
      "Core: 12, all 15 images processed\n",
      "Core: 13, all 15 images processed\n",
      "Core: 11, all 15 images processed\n",
      "Core: 0, all 16 images processed\n",
      "Core: 7, all 16 images processed\n",
      "Core: 10, all 16 images processed\n",
      "Core: 1, all 16 images processed\n",
      "Core: 18, all 15 images processed\n",
      "Core: 4, all 16 images processed\n",
      "Core: 2, all 16 images processed\n",
      "Core: 19, all 15 images processed\n",
      "Core: 6, all 16 images processed\n",
      "Core: 9, all 16 images processed\n",
      "Core: 16, all 15 images processed\n",
      "Core: 8, all 16 images processed\n",
      "Core: 5, all 16 images processed\n",
      "Core: 3, all 16 images processed\n",
      "Core: 17, all 15 images processed\n",
      "Time elapsed: 6.77 seconds\n"
     ]
    }
   ],
   "source": [
    "#!python panopticapi/converters/panoptic2semantic_segmentation.py \\\n",
    "#--input_json_file Rellis_labels/annotations_val_panoptic.json \\\n",
    "#--segmentations_folder Rellis_labels/val_panoptic/ \\\n",
    "#--semantic_seg_folder Rellis_labels/val_semantic \\\n",
    "#--categories_json_file Rellis_labels/categories.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING FROM...\n",
      "COCO panoptic format:\n",
      "\tSegmentation folder: Rellis_labels/test_panoptic/\n",
      "\tJSON file: Rellis_labels/annotations_test_panoptic.json\n",
      "SEMANTIC SEGMENTATION\n",
      "in PNG format:\n",
      "\tFolder with semnatic segmentations: Rellis_labels/test_semantic\n",
      "Creating folder Rellis_labels/test_semantic for semantic segmentation PNGs\n",
      "\n",
      "\n",
      "Number of cores: 20, images per core: 32\n",
      "Core: 0, 0 from 32 images processed\n",
      "Core: 1, 0 from 32 images processed\n",
      "Core: 2, 0 from 32 images processed\n",
      "Core: 3, 0 from 32 images processed\n",
      "Core: 4, 0 from 31 images processed\n",
      "Core: 5, 0 from 31 images processed\n",
      "Core: 6, 0 from 31 images processed\n",
      "Core: 7, 0 from 31 images processed\n",
      "Core: 8, 0 from 31 images processed\n",
      "Core: 9, 0 from 31 images processed\n",
      "Core: 10, 0 from 31 images processed\n",
      "Core: 11, 0 from 31 images processed\n",
      "Core: 12, 0 from 31 images processed\n",
      "Core: 13, 0 from 31 images processed\n",
      "Core: 14, 0 from 31 images processed\n",
      "Core: 15, 0 from 31 images processed\n",
      "Core: 16, 0 from 31 images processed\n",
      "Core: 17, 0 from 31 images processed\n",
      "Core: 18, 0 from 31 images processed\n",
      "Core: 19, 0 from 31 images processed\n",
      "Core: 12, all 31 images processed\n",
      "Core: 6, all 31 images processed\n",
      "Core: 0, all 32 images processed\n",
      "Core: 7, all 31 images processed\n",
      "Core: 13, all 31 images processed\n",
      "Core: 9, all 31 images processed\n",
      "Core: 11, all 31 images processed\n",
      "Core: 14, all 31 images processed\n",
      "Core: 3, all 32 images processed\n",
      "Core: 10, all 31 images processed\n",
      "Core: 15, all 31 images processed\n",
      "Core: 18, all 31 images processed\n",
      "Core: 1, all 32 images processed\n",
      "Core: 8, all 31 images processed\n",
      "Core: 2, all 32 images processed\n",
      "Core: 4, all 31 images processed\n",
      "Core: 19, all 31 images processed\n",
      "Core: 16, all 31 images processed\n",
      "Core: 5, all 31 images processed\n",
      "Core: 17, all 31 images processed\n",
      "Time elapsed: 13.02 seconds\n"
     ]
    }
   ],
   "source": [
    "#!python panopticapi/converters/panoptic2semantic_segmentation.py \\\n",
    "#--input_json_file Rellis_labels/annotations_test_panoptic.json \\\n",
    "#--segmentations_folder Rellis_labels/test_panoptic/ \\\n",
    "#--semantic_seg_folder Rellis_labels/test_semantic \\\n",
    "#--categories_json_file Rellis_labels/categories.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXTRACTING FROM...\n",
      "COCO panoptic format:\n",
      "\tSegmentation folder: Rellis_labels/train_panoptic/\n",
      "\tJSON file: Rellis_labels/annotations_train_panoptic.json\n",
      "SEMANTIC SEGMENTATION\n",
      "in PNG format:\n",
      "\tFolder with semnatic segmentations: Rellis_labels/train_semantic\n",
      "Creating folder Rellis_labels/train_semantic for semantic segmentation PNGs\n",
      "\n",
      "\n",
      "Number of cores: 20, images per core: 265\n",
      "Core: 0, 0 from 265 images processed\n",
      "Core: 1, 0 from 265 images processed\n",
      "Core: 2, 0 from 265 images processed\n",
      "Core: 3, 0 from 265 images processed\n",
      "Core: 4, 0 from 265 images processed\n",
      "Core: 5, 0 from 265 images processed\n",
      "Core: 6, 0 from 265 images processed\n",
      "Core: 7, 0 from 265 images processed\n",
      "Core: 8, 0 from 265 images processed\n",
      "Core: 9, 0 from 265 images processed\n",
      "Core: 10, 0 from 265 images processed\n",
      "Core: 11, 0 from 265 images processed\n",
      "Core: 12, 0 from 265 images processed\n",
      "Core: 13, 0 from 265 images processed\n",
      "Core: 14, 0 from 265 images processed\n",
      "Core: 15, 0 from 265 images processed\n",
      "Core: 16, 0 from 265 images processed\n",
      "Core: 17, 0 from 265 images processed\n",
      "Core: 18, 0 from 264 images processed\n",
      "Core: 19, 0 from 264 images processed\n",
      "Core: 14, 100 from 265 images processed\n",
      "Core: 7, 100 from 265 images processed\n",
      "Core: 10, 100 from 265 images processed\n",
      "Core: 13, 100 from 265 images processed\n",
      "Core: 12, 100 from 265 images processed\n",
      "Core: 15, 100 from 265 images processed\n",
      "Core: 8, 100 from 265 images processed\n",
      "Core: 9, 100 from 265 images processed\n",
      "Core: 0, 100 from 265 images processed\n",
      "Core: 4, 100 from 265 images processed\n",
      "Core: 6, 100 from 265 images processed\n",
      "Core: 11, 100 from 265 images processed\n",
      "Core: 2, 100 from 265 images processed\n",
      "Core: 3, 100 from 265 images processed\n",
      "Core: 19, 100 from 264 images processed\n",
      "Core: 16, 100 from 265 images processed\n",
      "Core: 5, 100 from 265 images processed\n",
      "Core: 1, 100 from 265 images processed\n",
      "Core: 18, 100 from 264 images processed\n",
      "Core: 17, 100 from 265 images processed\n",
      "Core: 15, 200 from 265 images processed\n",
      "Core: 7, 200 from 265 images processed\n",
      "Core: 13, 200 from 265 images processed\n",
      "Core: 12, 200 from 265 images processed\n",
      "Core: 14, 200 from 265 images processed\n",
      "Core: 6, 200 from 265 images processed\n",
      "Core: 10, 200 from 265 images processed\n",
      "Core: 0, 200 from 265 images processed\n",
      "Core: 4, 200 from 265 images processed\n",
      "Core: 8, 200 from 265 images processed\n",
      "Core: 11, 200 from 265 images processed\n",
      "Core: 1, 200 from 265 images processed\n",
      "Core: 2, 200 from 265 images processed\n",
      "Core: 5, 200 from 265 images processed\n",
      "Core: 9, 200 from 265 images processed\n",
      "Core: 3, 200 from 265 images processed\n",
      "Core: 18, 200 from 264 images processed\n",
      "Core: 19, 200 from 264 images processed\n",
      "Core: 16, 200 from 265 images processed\n",
      "Core: 17, 200 from 265 images processed\n",
      "Core: 15, all 265 images processed\n",
      "Core: 7, all 265 images processed\n",
      "Core: 6, all 265 images processed\n",
      "Core: 13, all 265 images processed\n",
      "Core: 12, all 265 images processed\n",
      "Core: 14, all 265 images processed\n",
      "Core: 10, all 265 images processed\n",
      "Core: 8, all 265 images processed\n",
      "Core: 0, all 265 images processed\n",
      "Core: 11, all 265 images processed\n",
      "Core: 1, all 265 images processed\n",
      "Core: 9, all 265 images processed\n",
      "Core: 5, all 265 images processed\n",
      "Core: 2, all 265 images processed\n",
      "Core: 19, all 264 images processed\n",
      "Core: 4, all 265 images processed\n",
      "Core: 18, all 264 images processed\n",
      "Core: 3, all 265 images processed\n",
      "Core: 16, all 265 images processed\n",
      "Core: 17, all 265 images processed\n",
      "Time elapsed: 109.69 seconds\n"
     ]
    }
   ],
   "source": [
    "#!python panopticapi/converters/panoptic2semantic_segmentation.py \\\n",
    "#--input_json_file Rellis_labels/annotations_train_panoptic.json \\\n",
    "#--segmentations_folder Rellis_labels/train_panoptic/ \\\n",
    "#--semantic_seg_folder Rellis_labels/train_semantic \\\n",
    "#--categories_json_file Rellis_labels/categories.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "748bd798e6457780c1ca434660e09025058191c162a3f1250fcd4bce637b7827"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
